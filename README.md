<h1 align="center"> Case: Qualidade do Ar </h1>

![Badge em Desenvolvimento](https://img.shields.io/static/v1?label=STATUS&message=COMPLETO&color=<COLOR>)

<h1 align ="center"> Objetivo do Caseü§î</h1>

Utilizando Python, estat√≠stica e Machine Learning este case objetiva analisar dados de sensores qu√≠micos localizados numa cidade significativamente polu√≠da, gerando conhecimento sobre o n√≠vel de concentra√ß√£o de mon√≥xido de carbono na cidade e criando um modelo capaz de predizer o n√≠vel de concentra√ß√£o do g√°s na atmosfera. 


<h1 align ="center"> Compreens√£o do Problema</h1>

Mon√≥xido de Carbono √© um g√°s poluente e t√≥xico para sa√∫de dos seres vivos. Ele √© fruto de processos de combust√£o e por isso √© encontrados cidades que passam por desmatamento, queimadas ou que tenham alto fluxo de ve√≠culos. Mon√≥xido de carbono √© um dos gases liberados por ve√≠culos a base de combust√≠vel, e seu n√≠vel de concentra√ß√£o pode depender de muitos fatores uma vez que a rea√ß√£o com outras subst√¢ncias √© poss√≠vel.  

Neste projeto √© importante notar que:
1. O dia e a hora pode ser um fator importante para a concetra√ß√£o
2. Outros gases podem estar presentes e afetar a concentra√ß√£o do mesmo.
   
Em contexto de m√©trica de avalia√ß√£o do modelo tem:
1. Raiz do erro m√©dio quadr√°tico
2. Coeficiente R¬≤


<h1 align ="center"> Resumos das Etapas</h1>

<h2 align ="left"> Tratamento dos Dados</h2>

Realizei tratamento dos dados. Este processo contou as etapas de leitura dos dados, obten√ß√£o de informa√ß√µes b√°sicas do dataset, buscando inconsist√™nicias como valores duplicados e faltantes. Corre√ß√µes foram feitas nas inconsit√™ncias encontradas, criando colunas que informam a exist√™ncia de valores faltantes para levar para An√°lise Explorat√≥ria e para o Modelo de Regress√£o.


* Analisei os tipos de dados;
* Como Lidei com Valores Nulos:
  1. Todos os valores *-200* representavam dados faltantes, logo os troquei por *NaN*
  2. Criei de Novas colunas que informam se os dados eras faltantes.
  3. Usei do Simple Imputer para substituit os valores Nulos.
     
* Avaliei e retirei duplicatas;
* Criei novo arquivo para An√°lise Explorat√≥ria.

<h2 align ="left"> An√°lise Explorat√≥ria e Explanat√≥ria</h2>

Realizei an√°lise estat√≠stica descritiva univariadas e bivariadas das features, observando sua distribui√ß√£o e correla√ß√£o entre features. Anotei quais eram as features com correla√ß√µes acima de 0.95 para retirar na cria√ß√£o do modelo. Calculei quais eram as vari√°veis mais correlacionadas ao vari√°veis Target.

![Corr_target](https://github.com/user-attachments/assets/0f9553c7-7403-48d6-a4e3-5ba70ef428f5)

O gr√°fico de barras acima mostra quais as cincos features mais correlacionadas com a concentra√ß√£o de CO, todos s√£o outras subst√¢ncias qu√≠micas indicando que geralmente a presen√ßa destas subst√¢ncias indica presen√ßa de mon√≥xido de carbono tamb√©m. 

Calculei qual dia da semana h√° a maior mediana na concetra√ß√£o de CO.

![dia_semana](https://github.com/user-attachments/assets/7d33b611-0476-416b-9118-6637f0d0d8e1)

Quinta-Feira √© o dia com a maior mediana na concentra√ß√£o de mon√≥xido de carbono. 

![download](https://github.com/user-attachments/assets/f28ac8c0-97cd-4fd0-9867-85c27c79ad82)

E na quinta-feira a concentra√ß√£o do g√°s tem pico as 8h da manh√£ e as 18h, hor√°rios que iniciam e terminam o per√≠odo comercial. Desta forma os picos de Mon√≥xidos podem estar relacionados com entrada e sa√≠da dos trabalhadores ao trabalho. 



**A an√°lise explorat√≥ria envolveu:**

* An√°lise da vari√°vel target, visualiza√ß√£o de distribui√ß√£o
* An√°lise de dados qualitativos e quantitativos
* An√°lise bivariada entre grupos da vari√°vel target
* Data visualization
* Storytelling

 
<h2 align ="left"> Cria√ß√£o do Modelo Regress√£o</h2>

**O treinamento do modelo envolveu:**

* An√°lise de Correla√ß√£o e retirada de features multicolineares;
* Category Encoder com BinaryEncoder;
* Padroniza√ß√£o dos dados com StandardScaler;
* Defini√ß√£o da Baseline com *regress√£o linear* e  *RMSE*: 73.72%;
* Separa√ß√£o de dados de treino e teste; 
* Treinamento de modelos de regress√£o utilizando Valida√ß√£o Cruzada e KFold;
* Otimiza√ß√£o por Hiperpar√¢metros do melhor modelo usando GridSearchCV;
* Teste do modelo otimizado.

 <h3 align ="left"> Sobre a escolha da m√©trica</h3>

 A m√©trica escolhida foi *Root Mean Squared Error* para representar o erro do modelo ao predizer um valor. A escolha desta m√©trica se deve aos fatos:

 1. RMSE √© uma m√©trica que √© afetada por valores outliers, assim utilizando ela √© poss√≠vel verificar se o modelo est√° conseguindo se adequar inclusive aos valores mais discrepantes.
 2. RMSE est√° na unidade correta para fazer a avalia√ß√£o do modelo, diferente de MSE.

 
  
<h3 align ="left"> Resultados do Modelo</h3>

O modelo apresentou os seguintes resultados finais, ap√≥s avalia√ß√£o do ponto de threashold que maximiza os lucros:

| M√©trica                             | Valor             |
|-------------------------------------|-------------------|
| RMSE                        | 45,62               |

Esta m√©trica mostra que o modelo consegue predizer bem os valores, como ser√° mostrado nos gr√°ficos a seguir.

![download](https://github.com/user-attachments/assets/e7e769ae-ed2f-41b2-a1df-ecbc154403ab)

O gr√°fico de res√≠dios acima mostra que n√£o h√° padr√£o presente nos erros e portante o modelo n√£o est√° apresentando tend√™ncias nos erros. 

![download](https://github.com/user-attachments/assets/7f8717d9-25fd-4806-b18a-6f73a31b3d50)

O gr√°fico de Preditos em fun√ß√£o dos Reais acima mostra que o modelo est√° tendo bom poder de predi√ß√£o j√° que existe correla√ß√£o linear entres dados reais e de predi√ß√£o. 

Por fim, as features com mais import√¢ncia ao modelo est√£o representadas abaixo:

![download](https://github.com/user-attachments/assets/bc999ea5-3511-4497-9ba6-f2cf80c69a07)

Top 10 features com mais import√¢ncia para o modelo, que est√° seguindo o padr√£o das features mais correlacionadas mostradas na an√°lise explorat√≥ria. 


<h2 align ="center"> Pr√≥ximas Etapas</h2>

Os resultados finais apresentados foram obtidos com dados de valida√ß√£o do modelos, o que mostra que o modelo perfomaria bem no dia a dia. O pr√≥ximo passo seria fazer o deploy do modelo, para ser utilizado pela empresa durante o dia a dia. 


<h2 align ="center"> Quais bibliotecas usei durante o Case?</h2>

1. Tratamento: Pandas üêº, Sklearn.impute|
2. An√°lise Explorat√≥ria: Numpy, scipy, matplotlib, seaborn|
3. Cria√ß√£o do Modelo: Sklearn, category encoders, Pickle|

## Detalhes do projeto


Os dados deste case foram retirados do P.E.D, e voc√™ pode acessar o P.E.D [aqui](https://www.renatabiaggi.com/ped). 



<h2 align ="center">Autor üöÄ</h2>
<a>
<img style = "border-radius: 50%;" src = https://github.com/KaueAbbe/Analise_ChurnRate/assets/68445400/bd4b5b79-4826-4d72-91e4-5fc7532ac19b width="250px;" alt=""/>

 <sub><b></b></sub></a> 

<h4> Feito com üíô por Kaue Hermann Abbehausen üëãüèΩ 
<br/> 

 
 1.Cientista de Dados
 
 2. Formado em F√≠sica na Universidade Federal de Uberl√¢ndia
 
 3. Mestre em F√≠sica Estat√≠stica na Universidade de Bras√≠lia</h4>
<h4> Entre em contato por</h4>
<div align = "center"> 

<div align = "center"> 
   <a href="https://www.linkedin.com/in/kaue-abbehausen-5b1922165/" target="_blank"><img src="https://img.shields.io/badge/-LinkedIn-%230077B5?style=for-the-badge&logo=linkedin&logoColor=white" target="_blank"></a> 
  <a href="https://www.instagram.com/kaue.hermann/" target="_blank"><img src="https://img.shields.io/badge/-Instagram-%23E4405F?style=for-the-badge&logo=instagram&logoColor=white" target="_blank"></a>
  <a href = "mailto:kaueabbehausen@gmail.com"><img src="https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=gmail&logoColor=white"></a>
</div>
